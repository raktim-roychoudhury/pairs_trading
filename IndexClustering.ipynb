{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VhIDin9kV8pg"},"outputs":[],"source":["!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n","!tar -xzvf ta-lib-0.4.0-src.tar.gz\n","%cd ta-lib\n","!./configure --prefix=/usr\n","!make\n","!make install\n","!pip install Ta-Lib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Y9DFaEgpAZy"},"outputs":[],"source":["cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTTcYDerjgoP"},"outputs":[],"source":["!pip install yfinance\n","!pip install phik"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kyMM-N7XcA0"},"outputs":[],"source":["import talib as ta\n","import pandas as pd\n","import numpy as np\n","import yfinance as yf\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["def load_data(filepath = 'fundamentals.csv'):\n","    \n","    #read data\n","    raw_data = pd.read_csv(filepath, low_memory = False);\n","    \n","    #get the keys (indices)\n","    indices = raw_data.keys()\n","    \n","    #rename the columns to features\n","    raw_data.rename(columns = raw_data.iloc[0], inplace = True)\n","    \n","    #drop columns from data values\n","    raw_data.drop([0], inplace = True)\n","    \n","    #set dates as index\n","    raw_data.set_index(\"Dates\", inplace = True)\n","    \n","    #extract list of indices\n","    indices = indices.to_list()\n","    indices = indices[1:]\n","    \n","    final_indices = []\n","    \n","    for i in range(len(indices)):\n","        if i%23 == 0:\n","            final_indices.append(indices[i])\n","     \n","    columns = []\n","    for i in raw_data.keys():\n","        columns.append(i)\n","    \n","    #make the columns unique\n","    temp_columns = columns.copy()\n","    for i in range(len(columns)):\n","        temp_columns[i] = temp_columns[i] + \" \"+ final_indices[int(i/23)]\n","    \n","    #drop first row\n","    raw_data.drop(\"01-01-2010\", inplace = True)\n","    \n","    #rename columns\n","    raw_data.columns = temp_columns\n","    \n","    #get list of features\n","    final_columns = [];\n","    [final_columns.append(x) for x in columns if x not in final_columns];\n","    \n","    #make a 3d dataframe\n","    final_dict = {}\n","    for i in range(len(raw_data.keys())):\n","        final_dict[final_indices[int(i/23)], final_columns[i%23]] = raw_data[raw_data.keys()[i]]\n","        \n","    final_raw_data = pd.DataFrame(final_dict)\n","    \n","    #get all the indices where all data is present\n","    temp_dict = {}\n","    for outer_key in final_indices:\n","        if len(final_raw_data[outer_key].dropna(axis = 1).keys()) == 23:\n","            for inner_key in final_raw_data[outer_key].keys():\n","                temp_dict[outer_key, inner_key] = final_raw_data[outer_key][inner_key]\n","    \n","    final_df = pd.DataFrame(temp_dict)\n","    \n","    return final_df"],"metadata":{"id":"SxO1VnzymGU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"R17_6B7RZVFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = load_data('/content/drive/MyDrive/IAQF/fundamentals.csv')\n","data"],"metadata":{"id":"PrXwiOpYnGt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Taking only 680 days of data\n","\"\"\"\n","data = data[-680:-1].copy()\n","data\n","\"\"\""],"metadata":{"id":"DOVOnFq-y30G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["indices = list(data.columns.get_level_values(0).unique())\n","print(indices)"],"metadata":{"id":"HPSMp5v5nPk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.rename(columns = {'PX_OPEN': 'Open', 'PX_LOW' : 'Low', 'PX_LAST' : 'Close', 'PX_HIGH' : 'High','PX_VOLUME' : 'Volume'}, inplace = True)\n","data"],"metadata":{"id":"Nz7byq_UoLYi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.loc[:,('SPX Index', 'Close')] = data.loc[:,('SPX Index', 'Close')].astype(np.float32)\n","data.loc[:,('SPX Index', 'Close')]"],"metadata":{"id":"6nZ5Eq7du0lU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lx8Z7XNLZop6"},"outputs":[],"source":["index_dict = {}\n","for index in indices :\n","  df = data[index].copy()\n","  df = df.astype(np.float32)\n","  df.dropna(inplace = True, axis = 0)\n","  df['RSI'] = ta.RSI(df['Close'])\n","  df['MFI'] = ta.MFI(df['High'],df['Low'],df['Close'], df['Volume'])\n","  df['ADX'] = ta.MFI(df['High'],df['Low'],df['Close'], df['Volume'])\n","  df['OBV'] = ta.OBV(df['Close'], df['Volume'])\n","  df['ATR'] = ta.ATR(df['High'], df['Low'], df['Close'])\n","  df['Boll_upper'], df['Boll_mid'], df['Boll_lower'] = ta.BBANDS(df['Close'], timeperiod = 20)\n","  df['EMA'] = ta.EMA(df['Close'], timeperiod = 14)\n","  df['MACD'],_,_ = ta.MACD(df['Close'],fastperiod = 14, slowperiod = 30)\n","  for i in range(1,49) :\n","    df['LR_' + str(i)] = np.log(df['Close']) - np.log(df['Close'].shift(i))\n","  for col in df.columns:\n","    df[col] = (df[col] - df[col].min())/(df[col].max() - df[col].min())\n","  df.dropna(inplace = True, axis = 0)\n","  index_dict[index] = df"]},{"cell_type":"code","source":["index_dict[indices[0]]['PX_TO_BOOK_RATIO']"],"metadata":{"id":"xwdUJnf8tlyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index_keys = list(index_dict.keys())\n","for index in index_keys:\n","  if (index_dict[index].shape[0] == 0):\n","    del(index_dict[index])"],"metadata":{"id":"jtWfVyDn-Knk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Vgu7UPYNJTr"},"outputs":[],"source":["for index in index_dict:\n","  print(index_dict[index].shape)"]},{"cell_type":"code","source":["indices = list(index_dict.keys())\n","indices"],"metadata":{"id":"If-NtOPS9l2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFb_Ao81evqX"},"outputs":[],"source":["reformed_dict = {}\n","for outerKey, innerDict in index_dict.items():\n","    for innerKey, values in innerDict.items():\n","        reformed_dict[(outerKey,\n","                       innerKey)] = values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgY4ShlxxpYI"},"outputs":[],"source":["data = pd.DataFrame(reformed_dict)\n","data.shape"]},{"cell_type":"code","source":["data.isna()"],"metadata":{"id":"dk9pAtzO7f1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5hcl8UGHdXv"},"outputs":[],"source":["from keras.layers import Conv2D, Conv2DTranspose, Dense, Flatten, Reshape\n","from keras.models import Sequential, Model\n","from keras.utils.vis_utils import plot_model\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dkEzIs7cHolo"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n","\n","nmi = normalized_mutual_info_score\n","ari = adjusted_rand_score\n","\n","def acc(y_true, y_pred):\n","    \"\"\"\n","    Calculate clustering accuracy. Require scikit-learn installed\n","    # Arguments\n","        y: true labels, numpy.array with shape `(n_samples,)`\n","        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n","    # Return\n","        accuracy, in [0,1]\n","    \"\"\"\n","    y_true = y_true.astype(np.int64)\n","    assert y_pred.size == y_true.size\n","    D = max(y_pred.max(), y_true.max()) + 1\n","    w = np.zeros((D, D), dtype=np.int64)\n","    for i in range(y_pred.size):\n","        w[y_pred[i], y_true[i]] += 1\n","    from sklearn.utils.linear_assignment_ import linear_assignment\n","    ind = linear_assignment(w.max() - w)\n","    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pLXUMseIHNh"},"outputs":[],"source":["args = {\n","        'n_clusters' : 10,\n","        'batch_size' : 32,\n","        'epochs' : 1000,\n","        'save_dir' : 'results/temp'\n","}\n","print(args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBtrPnfKIQK6"},"outputs":[],"source":["import os\n","if not os.path.exists(args['save_dir']):\n","  os.makedirs(args['save_dir'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQegvaHQIZC0"},"outputs":[],"source":["# load dataset\n","#data = pd.read_csv('data_processed.csv', header=[0,1], index_col=0)\n","#data.dropna(inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTbOkCMuyhdf"},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hmgb-agRC_f9"},"outputs":[],"source":["print(f'No. of indices = {len(indices)}')\n","print(indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMSpnZcoUIN1"},"outputs":[],"source":["n_timesteps = data.shape[0]\n","n_features = data[indices[0]].shape[1]\n","n_indices = int(data.shape[1]/data[indices[0]].shape[1])\n","print(f'n_timesteps : {n_timesteps}, n_features : {n_features}, n_indices : {n_indices}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MQlfMWtNydti"},"outputs":[],"source":["x = data.values\n","x = x.reshape(-1, n_timesteps, n_features,1).astype('float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQ2hNE7B569o"},"outputs":[],"source":["x.shape"]},{"cell_type":"code","source":["x"],"metadata":{"id":"Q4Aw3-xCgXEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data.columns.get_level_values(1).unique())"],"metadata":{"id":"LrVAWDPPZ_UX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVYFQIaFzYpJ"},"outputs":[],"source":["model = Sequential()\n","input_shape = x.shape[1:]\n","filters = [32, 64, 128, 10]\n","\n","#encoding layer\n","if input_shape[0] % 8 == 0:\n","    pad3 = 'same'\n","else:\n","    pad3 = 'valid'\n","model.add(Conv2D(filters[0], 5, strides=1, padding='same', activation='relu', name='conv1', input_shape=input_shape))\n","\n","model.add(Conv2D(filters[1], 5, strides=1, padding='same', activation='relu', name='conv2'))\n","\n","model.add(Conv2D(filters[2], 3, strides=1, padding=pad3, activation='relu', name='conv3'))\n","\n","model.add(Flatten(name = 'flatten'))\n","model.add(Dense(units=filters[3], name='embedding'))\n","model.add(Dense(units = model.get_layer(name='flatten').output_shape[-1], activation = 'relu'))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHtZ1tJ1z1Gy"},"outputs":[],"source":["#decoding layers\n","\n","model.add(Reshape((input_shape[0]-2, input_shape[1] - 2, filters[2])))\n","\n","model.add(Conv2DTranspose(filters[1], 3, strides=1, padding=pad3, activation='relu', name='deconv3'))\n","\n","model.add(Conv2DTranspose(filters[0], 5, strides=1, padding='same', activation='relu', name='deconv2'))\n","\n","model.add(Conv2DTranspose(input_shape[2], 5, strides=1, padding='same', name='deconv1'))\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5MRN2-mIiYu"},"outputs":[],"source":["# define the model\n","plot_model(model, to_file=args['save_dir'] + '/%s-pretrain-model.png' % 'data', show_shapes=True)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9mbBSxgMO6u"},"outputs":[],"source":["# compile the model and callbacks\n","optimizer = 'adam'\n","model.compile(optimizer=optimizer, loss='mse')\n","from keras.callbacks import CSVLogger\n","csv_logger = CSVLogger(args['save_dir'] + '/%s-pretrain-log.csv' % 'data')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhN4Z52ufW-p"},"outputs":[],"source":["import tensorflow as tf\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 5)\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'best_model.h5', monitor = 'loss', save_best_only = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlwnKU-OMU-A"},"outputs":[],"source":["# begin training\n","from time import time\n","t0 = time()\n","history = model.fit(x, x, batch_size=args['batch_size'], epochs=args['epochs'],verbose = 1, callbacks=[model_checkpoint,csv_logger)\n","print('Training time: ', time() - t0)\n","model.save(args['save_dir'] + '/%s-pretrain-model-%d.h5' % ('data', args['epochs']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FyPrMp8S8hMc"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","training_loss = history.history['loss']\n","epoch_count = range(1, len(training_loss) + 1)\n","plt.figure(figsize = (25,5))\n","plt.plot(epoch_count[2:], training_loss[2:], \"r--\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend([\"Training Loss\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgnH-GxMYLHy"},"outputs":[],"source":["# extract features\n","feature_model = Model(inputs=model.input, outputs=model.get_layer(name='embedding').output)\n","features = feature_model.predict(x)\n","print('feature shape=', features.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aXBn9CwLYVkx"},"outputs":[],"source":["from sklearn.cluster import AgglomerativeClustering\n","Agg_Clustering = AgglomerativeClustering(n_clusters = 10)\n","features = np.reshape(features, newshape = (features.shape[0], -1))\n","pred = Agg_Clustering.fit_predict(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7qCmfB_Z8bW"},"outputs":[],"source":["pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fOjjaqlA1M-"},"outputs":[],"source":["indices = np.array(indices)\n","indices.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOrwX0jkrg3y"},"outputs":[],"source":["clustered_data = np.vstack((indices, pred)).T"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eRwofmPqJAg"},"outputs":[],"source":["cluster_df = pd.DataFrame(clustered_data, columns = ['Index','Cluster'])\n","cluster_df['Cluster'] = cluster_df['Cluster'].astype(np.int32)\n","cluster_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTXtY5cl9R7C"},"outputs":[],"source":["cluster_df.to_csv('cluster_Index_data_latest.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkOUYGFFqn_e"},"outputs":[],"source":["index_clusters = {}\n","for i in range(len(cluster_df)):\n","  if cluster_df['Cluster'].iloc[i] in stock_clusters:\n","    stock_clusters[cluster_df['Cluster'].iloc[i]].append(cluster_df['Index'].iloc[i])\n","  else:\n","    stock_clusters[cluster_df['Cluster'].iloc[i]] = [cluster_df['Index'].iloc[i]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hm-h417RzzdS"},"outputs":[],"source":["categories = cluster_df['Cluster'].unique()\n","categories.sort()\n","for i in categories:\n","  print(f'Cluster {i} : {stock_clusters[i]}')\n","  print('\\n')"]},{"cell_type":"code","source":["data = load_data()"],"metadata":{"id":"CO7RhPOKIB1k"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ciNJdxAz3r9p"},"outputs":[],"source":["import matplotlib.dates as mdates\n","\n","s1 = 'NDQ Index'\n","s2 = 'SBF120 Index'\n","\n","s1 = data[s1]['PX_LAST'][-360*5:].copy()\n","s1 = s1.astype(np.float32)\n","s2 = data[s2]['PX_LAST'][-360*5:].copy()\n","s2 = s2.astype(np.float32)\n","\n","s1 = (s1 - s1.min())/(s1.max() - s1.min())\n","s2 = (s2 - s2.min())/(s2.max() - s2.min())\n","\n","fig, ax = plt.subplots(figsize = (25,5))\n","\n","ax.plot(s1, label = s1)\n","ax.plot(s2, label = s2)\n","\n","start, end = ax.get_xlim()\n","ax.xaxis.set_ticks(np.arange(start, end, 180))\n","\n","\n","plt.ylabel('Close Price')\n","plt.xlabel('Date')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}